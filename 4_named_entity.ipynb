{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4_named_entity.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/otanet/hannari_NLP_hands_on_2022/blob/main/4_named_entity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXuO5xYCydgJ"
      },
      "source": [
        "# GiNZAのインストール\n",
        "!pip install ginza==4.0.5\n",
        "\n",
        "# メニュー「ランタイム → ランタイムを再起動」で「Google Colab」を再起動"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BG-SWPL5QRAx"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7Pn0Zc_yohy"
      },
      "source": [
        "import spacy\n",
        "from spacy import displacy\n",
        "nlp = spacy.load('ja_ginza')\n",
        "doc = nlp('山田さんと銀座でランチをご一緒しましょう。')\n",
        "\n",
        "# 固有表現抽出\n",
        "for ent in doc.ents:\n",
        "    print(\n",
        "        ent.text+','+ # テキスト\n",
        "        ent.label_+','+ # ラベル\n",
        "        str(ent.start_char)+','+ # 開始位置\n",
        "        str(ent.end_char)) # 終了位置\n",
        "\n",
        "# 固有表現抽出の強調表示\n",
        "displacy.render(doc, style='ent', jupyter=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbdnCOGV4oSt"
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load('ja_ginza')\n",
        "\n",
        "# 固有表現抽出\n",
        "doc = nlp('サツキと妹のメイは、母の療養のために父と一緒に農村へ引っ越してきた。')\n",
        "for ent in doc.ents:\n",
        "    print(\n",
        "        ent.text+','+ # テキスト\n",
        "        ent.label_+','+ # ラベル\n",
        "        str(ent.start_char)+','+ # 開始位置\n",
        "        str(ent.end_char) # 終了位置\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kwx_-WN53hft"
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load('ja_ginza')\n",
        "\n",
        "# 固有表現ルールの追加\n",
        "from spacy.pipeline import EntityRuler\n",
        "ruler = EntityRuler(nlp)\n",
        "ruler.add_patterns([\n",
        "    {'label': 'Person', 'pattern': 'サツキ'},\n",
        "    {'label': 'Person', 'pattern': 'メイ'}])\n",
        "nlp.add_pipe(ruler)\n",
        "\n",
        "# 固有表現抽出\n",
        "doc = nlp('サツキと妹のメイは、母の療養のために父と一緒に農村へ引っ越してきた。')\n",
        "for ent in doc.ents:\n",
        "    print(\n",
        "        ent.text+','+ # テキスト\n",
        "        ent.label_+','+ # ラベル\n",
        "        str(ent.start_char)+','+ # 開始位置\n",
        "        str(ent.end_char)) # 終了位置"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbKND7oq4NLF"
      },
      "source": [
        "import spacy\n",
        "import random\n",
        "\n",
        "# 固有抽出表現モデルの学習の関数定義\n",
        "def train_ner(train_data, epoch):\n",
        "    # 日本語の空モデルの生成\n",
        "    nlp = spacy.blank('ja')\n",
        "\n",
        "    # 固有表現抽出モデルのパイプの追加\n",
        "    if 'ner' not in nlp.pipe_names:\n",
        "        ner = nlp.create_pipe('ner')\n",
        "        nlp.add_pipe(ner, last=True)\n",
        "\n",
        "    # ラベルの追加\n",
        "    for _, annotations in train_data:\n",
        "        for ent in annotations.get('entities'):\n",
        "            ner.add_label(ent[2])\n",
        "\n",
        "    # 固有表現抽出モデルのみ学習\n",
        "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n",
        "    with nlp.disable_pipes(*other_pipes):\n",
        "        optimizer = nlp.begin_training()\n",
        "       \n",
        "        # 学習ループ\n",
        "        for itn in range(epoch):\n",
        "            # シャッフル\n",
        "            random.shuffle(train_data)\n",
        "           \n",
        "            # 学習\n",
        "            losses = {}\n",
        "            for text, annotations in train_data:\n",
        "                nlp.update([text], [annotations], drop=0.2, sgd=optimizer, losses=losses)\n",
        "            print('iteration'+str(itn)+': '+str(losses['ner']))\n",
        "    return nlp\n",
        "\n",
        "# 学習データの準備\n",
        "train_data = [\n",
        "    ('入院している母のお見舞いに行ったサツキとメイはオバケ屋敷のことを報告した。', \n",
        "        {'entities': [(16, 19, 'Person'),(20, 22, 'Person')]}),\n",
        "    ('サツキとメイが森のバス停で雨の中父の帰りを待っている。', \n",
        "        {'entities': [(0, 3, 'Person'), (4, 6, 'Person')]}),\n",
        "    ('1人で遊んでいたメイは庭で不思議な生き物を見つけた。', \n",
        "        {'entities': [(8, 10, 'Person')]}),\n",
        "    ('人が住み始めるといつのまにか居なくなるという話を聞いてサツキは拍子抜けした。', \n",
        "        {'entities': [(27, 30, 'Person')]})\n",
        "]\n",
        "\n",
        "# 固有表現抽出モデルの学習\n",
        "nlp = train_ner(train_data, 100)\n",
        "\n",
        "# 固有表現抽出モデルの保存\n",
        "nlp.to_disk('ner_model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DHhpWwn7DF9"
      },
      "source": [
        "import spacy\n",
        "\n",
        "# 固有表現抽出モデルの読み込み\n",
        "nlp = spacy.load('ner_model')\n",
        "\n",
        "# 固有表現抽出\n",
        "doc = nlp('サツキと妹のメイは、母の療養のために父と一緒に農村へ引っ越してきた。')\n",
        "for ent in doc.ents:\n",
        "    print(\n",
        "        ent.text+','+ # テキスト\n",
        "        ent.label_+','+ # ラベル\n",
        "        str(ent.start_char)+','+ # 開始位置\n",
        "        str(ent.end_char) # 終了位置\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWWRA3l-ozTB"
      },
      "source": [
        "%%time\n",
        "import spacy\n",
        "import random\n",
        "\n",
        "# 固有抽出表現モデルの学習の関数定義\n",
        "def train_ner(train_data, epoch):\n",
        "    # 日本語の空モデルの生成\n",
        "    nlp = spacy.blank('ja')\n",
        "\n",
        "    # 固有表現抽出モデルのパイプの追加\n",
        "    if 'ner' not in nlp.pipe_names:\n",
        "        ner = nlp.create_pipe('ner')\n",
        "        nlp.add_pipe(ner, last=True)\n",
        "\n",
        "    # ラベルの追加\n",
        "    for _, annotations in train_data:\n",
        "        for ent in annotations.get('entities'):\n",
        "            ner.add_label(ent[2])\n",
        "\n",
        "    # 固有表現抽出モデルのみ学習\n",
        "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n",
        "    with nlp.disable_pipes(*other_pipes):\n",
        "        optimizer = nlp.begin_training()\n",
        "       \n",
        "        # 学習ループ\n",
        "        for itn in range(epoch):\n",
        "            # シャッフル\n",
        "            random.shuffle(train_data)\n",
        "           \n",
        "            # 学習\n",
        "            losses = {}\n",
        "            for text, annotations in train_data:\n",
        "                nlp.update([text], [annotations], drop=0.2, sgd=optimizer, losses=losses)\n",
        "            print('iteration{}: {:.8f}'.format(itn, losses['ner']))\n",
        "    return nlp\n",
        "\n",
        "# 学習データの準備\n",
        "train_data = [\n",
        "    ('入院している母のお見舞いに行ったサツキとメイはオバケ屋敷のことを報告した。', \n",
        "        {'entities': [(16, 19, 'Person'),(20, 22, 'Person')]}),\n",
        "    ('サツキとメイが森のバス停で雨の中父の帰りを待っている。', \n",
        "        {'entities': [(0, 3, 'Person'), (4, 6, 'Person')]}),\n",
        "    ('1人で遊んでいたメイは庭で不思議な生き物を見つけた。', \n",
        "        {'entities': [(8, 10, 'Person')]}),\n",
        "    ('人が住み始めるといつのまにか居なくなるという話を聞いてサツキは拍子抜けした。', \n",
        "        {'entities': [(27, 30, 'Person')]})\n",
        "]\n",
        "\n",
        "# 固有表現抽出モデルの学習\n",
        "nlp = train_ner(train_data, 50)\n",
        "\n",
        "# 固有表現抽出モデルの保存\n",
        "nlp.to_disk('ner_model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcX8q3YO7QYy"
      },
      "source": [
        "import spacy\n",
        "\n",
        "# 固有表現抽出モデルの読み込み\n",
        "nlp = spacy.load('ner_model')\n",
        "\n",
        "# 固有表現抽出\n",
        "doc = nlp('サツキと妹のメイは、母の療養のために父と一緒に農村へ引っ越してきた。')\n",
        "for ent in doc.ents:\n",
        "    print(\n",
        "        ent.text+','+ # テキスト\n",
        "        ent.label_+','+ # ラベル\n",
        "        str(ent.start_char)+','+ # 開始位置\n",
        "        str(ent.end_char) # 終了位置\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAHlZ7WKrK4O"
      },
      "source": [
        "%%time\n",
        "import spacy\n",
        "import random\n",
        "\n",
        "# 固有抽出表現モデルの学習の関数定義\n",
        "def train_ner(train_data, epoch):\n",
        "    # 日本語の空モデルの生成\n",
        "    nlp = spacy.blank('ja')\n",
        "\n",
        "    # 固有表現抽出モデルのパイプの追加\n",
        "    if 'ner' not in nlp.pipe_names:\n",
        "        ner = nlp.create_pipe('ner')\n",
        "        nlp.add_pipe(ner, last=True)\n",
        "\n",
        "    # ラベルの追加\n",
        "    for _, annotations in train_data:\n",
        "        for ent in annotations.get('entities'):\n",
        "            ner.add_label(ent[2])\n",
        "\n",
        "    # 固有表現抽出モデルのみ学習\n",
        "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n",
        "    with nlp.disable_pipes(*other_pipes):\n",
        "        optimizer = nlp.begin_training()\n",
        "       \n",
        "        # 学習ループ\n",
        "        for itn in range(epoch):\n",
        "            # シャッフル\n",
        "            random.shuffle(train_data)\n",
        "           \n",
        "            # 学習\n",
        "            losses = {}\n",
        "            for text, annotations in train_data:\n",
        "                nlp.update([text], [annotations], drop=0.2, sgd=optimizer, losses=losses)\n",
        "            print('iteration{}: {:.8f}'.format(itn, losses['ner']))\n",
        "    return nlp\n",
        "\n",
        "# 学習データの準備\n",
        "import json\n",
        "labels = {\n",
        "    '人名': 'Person',\n",
        "    '法人名': 'Juridical_Person',\n",
        "    '政治的組織名': 'Political_Organization',\n",
        "    'その他の組織名': 'Organization_Other',\n",
        "    '地名': 'Location',\n",
        "    '施設名': 'Facility',\n",
        "    '製品名': 'Product',\n",
        "    'イベント名': 'Event',\n",
        "}\n",
        "json_data = json.load(open('ner.json', 'r'))\n",
        "train_data = []\n",
        "for data in json_data:\n",
        "    text = data['text']\n",
        "    entities = data['entities']\n",
        "    value = []\n",
        "    for entity in entities:\n",
        "        span = entity['span']\n",
        "        label = labels[entity['type']]\n",
        "        value.append((span[0], span[1], label))\n",
        "    train_data.append((text, {'entities': value}))\n",
        "\n",
        "# 固有表現抽出モデルの学習\n",
        "nlp = train_ner(train_data, 50)\n",
        "\n",
        "# 固有表現抽出モデルの保存\n",
        "nlp.to_disk('ner_model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2GqZxmr4eBo"
      },
      "source": [
        "import spacy\n",
        "\n",
        "# 固有表現抽出モデルの読み込み\n",
        "nlp = spacy.load('ner_model')\n",
        "\n",
        "# 固有表現抽出\n",
        "doc = nlp('サツキと妹のメイは、母の療養のために父と一緒に農村へ引っ越してきた。')\n",
        "for ent in doc.ents:\n",
        "    print(\n",
        "        ent.text+','+ # テキスト\n",
        "        ent.label_+','+ # ラベル\n",
        "        str(ent.start_char)+','+ # 開始位置\n",
        "        str(ent.end_char) # 終了位置\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}