{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "chapter3_NLP-part1_20220131.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNP1rTpSBiPxiCaArdeHo+4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/otanet/hannari_NLP_hands_on_2022/blob/main/chapter3_NLP_part1_20220131.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GiNZAを用いた自然言語処理\n",
        "1. 形態素解析\n",
        "2. 係り受け解析\n",
        "3. 固有表現抽出\n",
        "4. NLPでよく用いられるルールベースマッチングや正規表現"
      ],
      "metadata": {
        "id": "I0L9rIcANcEt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### GiNZA\n",
        "1. GiNZAはspaCy, SudachiPy,をベースに構築されている。\n",
        "\n",
        "#### spaCy\n",
        "1. spaCyは多言語対応の深層学習ベースのライブラリで、プロダクト向けに設計されており、大量の文章の自然言語処理を扱える。\n",
        "\n",
        "#### SudachiPy\n",
        "- トークン単位の切り替え\n",
        "- 日本語収録語彙の多さ\n",
        "- 日本語の同義語辞書との連携\n",
        "- 機能にプラグイン"
      ],
      "metadata": {
        "id": "kbTRXsLVOUdU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GiNZAのインストール\n",
        "!pip install ginza==4.0.5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8qawqk2NbMm",
        "outputId": "23a6c9a8-b949-4125-d094-0615cbba44e2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ginza==4.0.5\n",
            "  Downloading ginza-4.0.5.tar.gz (20 kB)\n",
            "Collecting spacy<3.0.0,>=2.3.2\n",
            "  Downloading spacy-2.3.7-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.4 MB 5.2 MB/s \n",
            "\u001b[?25hCollecting ja_ginza<4.1.0,>=4.0.0\n",
            "  Downloading ja_ginza-4.0.0.tar.gz (51.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 51.5 MB 1.1 MB/s \n",
            "\u001b[?25hCollecting SudachiPy>=0.4.9\n",
            "  Downloading SudachiPy-0.6.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2 MB 41.1 MB/s \n",
            "\u001b[?25hCollecting SudachiDict-core>=20200330\n",
            "  Downloading SudachiDict-core-20211220.tar.gz (9.1 kB)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.3.2->ginza==4.0.5) (0.9.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.3.2->ginza==4.0.5) (1.1.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.3.2->ginza==4.0.5) (2.23.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.3.2->ginza==4.0.5) (1.0.6)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.3.2->ginza==4.0.5) (2.0.6)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.3.2->ginza==4.0.5) (3.0.6)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.3.2->ginza==4.0.5) (1.0.5)\n",
            "Collecting thinc<7.5.0,>=7.4.1\n",
            "  Downloading thinc-7.4.5-cp37-cp37m-manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 60.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.3.2->ginza==4.0.5) (1.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.3.2->ginza==4.0.5) (57.4.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.3.2->ginza==4.0.5) (1.19.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.3.2->ginza==4.0.5) (4.62.3)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.3.2->ginza==4.0.5) (0.4.1)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy<3.0.0,>=2.3.2->ginza==4.0.5) (4.10.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy<3.0.0,>=2.3.2->ginza==4.0.5) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy<3.0.0,>=2.3.2->ginza==4.0.5) (3.7.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0,>=2.3.2->ginza==4.0.5) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0,>=2.3.2->ginza==4.0.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0,>=2.3.2->ginza==4.0.5) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0,>=2.3.2->ginza==4.0.5) (1.24.3)\n",
            "Building wheels for collected packages: ginza, ja-ginza, SudachiDict-core\n",
            "  Building wheel for ginza (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ginza: filename=ginza-4.0.5-py3-none-any.whl size=15896 sha256=2b4715df03452b706548dc6bf305f2389e2fc1904759871a1d3d38e8b1b33590\n",
            "  Stored in directory: /root/.cache/pip/wheels/ba/a9/a2/c1165c004f6dcb415b7a7d145aa4511b5024b5fb1f2eb0c0ea\n",
            "  Building wheel for ja-ginza (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ja-ginza: filename=ja_ginza-4.0.0-py3-none-any.whl size=51530814 sha256=7ad4c33ff1745d115e8bfe7bf9f69c4d0460c755a3478719fda7c34e62b8a447\n",
            "  Stored in directory: /root/.cache/pip/wheels/a8/f5/4a/5d4877342f912e0b7209d8a65e7ce39fe2c1a3c2511d59acfb\n",
            "  Building wheel for SudachiDict-core (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for SudachiDict-core: filename=SudachiDict_core-20211220-py3-none-any.whl size=71565353 sha256=6eadd8541ea11fe53ee4f6e6012369d94db9e030103801d6bdaca5e630f6e962\n",
            "  Stored in directory: /root/.cache/pip/wheels/17/6d/f6/f9451cbfc76ffdf985af12239191ca20721f1da5aba5005eb0\n",
            "Successfully built ginza ja-ginza SudachiDict-core\n",
            "Installing collected packages: thinc, SudachiPy, spacy, SudachiDict-core, ja-ginza, ginza\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 7.4.0\n",
            "    Uninstalling thinc-7.4.0:\n",
            "      Successfully uninstalled thinc-7.4.0\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 2.2.4\n",
            "    Uninstalling spacy-2.2.4:\n",
            "      Successfully uninstalled spacy-2.2.4\n",
            "Successfully installed SudachiDict-core-20211220 SudachiPy-0.6.2 ginza-4.0.5 ja-ginza-4.0.0 spacy-2.3.7 thinc-7.4.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (注意)メニュー「ランタイム → ランタイムを再起動」で「Google Colab」を再起動。"
      ],
      "metadata": {
        "id": "f0QvLaGRRPJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load('ja_ginza')\n",
        "doc = nlp('銀座でランチをご一緒しましょう！')\n",
        "\n",
        "for token in doc:\n",
        "    print(token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ML2pWEWKNbPb",
        "outputId": "0a325d3f-bbc0-4964-a270-40f42fc52dca"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "銀座\n",
            "で\n",
            "ランチ\n",
            "を\n",
            "ご\n",
            "一緒\n",
            "し\n",
            "ましょう\n",
            "！\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 形態素解析\n",
        "# トークン化：文章を言葉の最小単位に分割する処理のこと。\n",
        "# 品詞タグ付け：トークンの品詞を判別する処理のこと。\n",
        "# レンマ化：トークンを辞書の見出し語に変換する処理のこと。"
      ],
      "metadata": {
        "id": "YNEViw8aNbSe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load('ja_ginza')\n",
        "doc = nlp('青い大きな目の猫')\n",
        "\n",
        "for token in doc:\n",
        "    print(token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uf7JTpM3NbU-",
        "outputId": "1d039d3d-47a9-4a86-b7c0-477ea22c0182"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "青い\n",
            "大きな\n",
            "目\n",
            "の\n",
            "猫\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 分割単位Aで分割する場合\n",
        "import spacy\n",
        "import ginza\n",
        "nlp = spacy.load('ja_ginza')\n",
        "ginza.set_split_mode(nlp, 'A') # 分割単位A\n",
        "doc = nlp('私は国家公務員です')\n",
        "\n",
        "for token in doc:\n",
        "    print(token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-JfRPKPNbdN",
        "outputId": "221921a3-c692-4add-bf95-3413c7fc18ed"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "私\n",
            "は\n",
            "国家\n",
            "公務\n",
            "員\n",
            "です\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 分割単位Bで分割する場合\n",
        "import spacy\n",
        "import ginza\n",
        "nlp = spacy.load('ja_ginza')\n",
        "ginza.set_split_mode(nlp, 'B') # 分割単位B\n",
        "doc = nlp('私は国家公務員です')\n",
        "\n",
        "for token in doc:\n",
        "    print(token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGR7fD3_Nbfs",
        "outputId": "d797b098-f86f-4731-9122-8bda0b326602"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "私\n",
            "は\n",
            "国家\n",
            "公務員\n",
            "です\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 分割単位Cで分割する場合\n",
        "import spacy\n",
        "import ginza\n",
        "nlp = spacy.load('ja_ginza')\n",
        "ginza.set_split_mode(nlp, 'C') # 分割単位C\n",
        "doc = nlp('私は国家公務員です')\n",
        "\n",
        "for token in doc:\n",
        "    print(token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yjbo4LTnUUS0",
        "outputId": "8b2b2200-780b-484e-ca05-64e3cc4239c0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "私\n",
            "は\n",
            "国家公務員\n",
            "です\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 品詞タグ付け\n",
        "import spacy\n",
        "nlp = spacy.load('ja_ginza')\n",
        "doc = nlp('銀座に行きます。')\n",
        "\n",
        "for token in doc:\n",
        "    print(\n",
        "        token.text+', '+ # テキスト\n",
        "        token.tag_+', '+ # SudachiPyの品詞タグ\n",
        "        token.pos_) # Universal Dependenciesの品詞タグ"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQ51ng7OUUWt",
        "outputId": "c421788a-16fc-4de8-de50-2531088b1d22"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "銀座, 名詞-固有名詞-地名-一般, PROPN\n",
            "に, 助詞-格助詞, ADP\n",
            "行き, 動詞-非自立可能, VERB\n",
            "ます, 助動詞, AUX\n",
            "。, 補助記号-句点, PUNCT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# レンマ化：トークンを辞書の見出し語に変換する処理のこと\n",
        "import spacy\n",
        "nlp = spacy.load('ja_ginza')\n",
        "doc = nlp('銀座に行きます。')\n",
        "\n",
        "for token in doc:\n",
        "    print(\n",
        "        token.text+', '+ # テキスト\n",
        "        token.lemma_) # レンマ化 "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VybFk7zbUUZj",
        "outputId": "9529017c-47c7-4763-dbfe-4964226dd7b7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "銀座, 銀座\n",
            "に, に\n",
            "行き, 行く\n",
            "ます, ます\n",
            "。, 。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 文境界解析\n",
        "import spacy\n",
        "nlp = spacy.load('ja_ginza')\n",
        "doc = nlp('銀座でランチをご一緒しましょう。今度の日曜日はどうですか。')\n",
        "\n",
        "# 文境界解析\n",
        "for span in doc.sents:\n",
        "    print(span)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CfCV5nICUUcB",
        "outputId": "8407d11e-8166-40ad-e4db-7ba9f79eb284"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "銀座でランチをご一緒しましょう。\n",
            "今度の日曜日はどうですか。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 文境界問題＋トークン化\n",
        "import spacy\n",
        "nlp = spacy.load('ja_ginza')\n",
        "doc = nlp('銀座でランチをご一緒しましょう。今度の日曜日はどうですか。')\n",
        "\n",
        "# 文境界解析+トークン化\n",
        "for span in doc.sents:\n",
        "    for token in span:\n",
        "        print(token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJu6M9GpWxMV",
        "outputId": "ff0ba410-4287-4dc0-8a28-c7a526384881"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "銀座\n",
            "で\n",
            "ランチ\n",
            "を\n",
            "ご\n",
            "一緒\n",
            "し\n",
            "ましょう\n",
            "。\n",
            "今度\n",
            "の\n",
            "日曜日\n",
            "は\n",
            "どう\n",
            "です\n",
            "か\n",
            "。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import ginza\n",
        "nlp = spacy.load('ja_ginza')\n",
        "doc = nlp('銀座でランチをご一緒しましょう。今度の日曜日はどうですか。')\n",
        "\n",
        "# 文節分割\n",
        "for sent in doc.sents:\n",
        "    for span in ginza.bunsetu_spans(sent):\n",
        "        print(span)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RoMSNWTlWyQt",
        "outputId": "03fa6e0f-9b1a-4692-d26d-969a4db00391"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "銀座で\n",
            "ランチを\n",
            "ご一緒しましょう。\n",
            "今度の\n",
            "日曜日は\n",
            "どうですか。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 文節分割\n",
        "import spacy\n",
        "import ginza\n",
        "nlp = spacy.load('ja_ginza')\n",
        "doc = nlp('銀座でランチをご一緒しましょう。今度の日曜日はどうですか。')\n",
        "\n",
        "# 文節分割+トークン化\n",
        "for sent in doc.sents:\n",
        "    for span in ginza.bunsetu_spans(sent):\n",
        "        for token in span:\n",
        "            print(token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCQFxIi6WyaL",
        "outputId": "76bb782e-d1f5-4c89-8f51-c18c9a444e47"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "銀座\n",
            "で\n",
            "ランチ\n",
            "を\n",
            "ご\n",
            "一緒\n",
            "し\n",
            "ましょう\n",
            "。\n",
            "今度\n",
            "の\n",
            "日曜日\n",
            "は\n",
            "どう\n",
            "です\n",
            "か\n",
            "。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ユーザー辞書への単語の追加(未知語の対応)\n",
        "import spacy\n",
        "nlp = spacy.load('ja_ginza')\n",
        "doc = nlp('となりのトトロが好き')\n",
        "\n",
        "#「となりのトトロ」が標準辞書で未対応であることを確認。\n",
        "for token in doc:\n",
        "    print(token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CASfOXC6Wyix",
        "outputId": "76e87f73-e44d-43ec-ee9c-68229e67346f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "となり\n",
            "の\n",
            "トトロ\n",
            "が\n",
            "好き\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 「user_dic.csv」のアップロード\n",
        "\n",
        "# ユーザー辞書のビルド\n",
        "!sudachipy ubuild -s /usr/local/lib/python3.7/dist-packages/sudachidict_core/resources/system.dic user_dic.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTTBh_i2X7gj",
        "outputId": "5350d069-e887-42e6-8e27-e5d3def5c95e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input file user_dic.csv does not exists\n",
            "usage: sudachipy ubuild [-h] [-d string] [-o file] [-s file] file [file ...]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pythonパッケージのパスの確認\n",
        "import sys\n",
        "print(sys.path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57-MeexzX8C0",
        "outputId": "8a00ac66-f3d4-4980-f997-c83b34cf4ba9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['', '/content', '/env/python', '/usr/lib/python37.zip', '/usr/lib/python3.7', '/usr/lib/python3.7/lib-dynload', '/usr/local/lib/python3.7/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.7/dist-packages/IPython/extensions', '/root/.ipython']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 「/usr/local/lib/python3.7/dist-packages/sudachipy/resources/sudachi.json」に「\"userDict\" : [\"/content/user.dic\"],」を追加\n",
        "!sudachipy ubuild -s /usr/local/lib/python3.7/dist-packages/sudachidict_core/resources/system.dic user_dic.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qB9fD-0wX8Ft",
        "outputId": "911fb16d-2f30-45a9-bc32-56d6a33c3b5a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input file user_dic.csv does not exists\n",
            "usage: sudachipy ubuild [-h] [-d string] [-o file] [-s file] file [file ...]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load('ja_ginza')\n",
        "doc = nlp('となりのトトロが好き')\n",
        "\n",
        "# ユーザー辞書で対応できたことを確認\n",
        "for token in doc:\n",
        "    print(token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uprKMQcuX8I0",
        "outputId": "d449e4ed-ad43-4358-fc5e-cc43048606bd"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "となり\n",
            "の\n",
            "トトロ\n",
            "が\n",
            "好き\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 要対応 Sudachiの辞書の追加をgithubで調べておくこと！"
      ],
      "metadata": {
        "id": "nXy4d-S8aEtP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 係り受け解析\n",
        "1. 文節の係り受け解析\n",
        "2. 単語の係り受け解析"
      ],
      "metadata": {
        "id": "Y-e6Q1cCai12"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "e3IaXyE-YQEJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "tuHkgyuYYQHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "AcBgp8wwX8LM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}