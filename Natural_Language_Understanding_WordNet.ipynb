{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Natural_Language_Understanding_WordNet",
      "provenance": [],
      "collapsed_sections": [
        "LGFil3SW_lEs"
      ],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/otanet/hannari_NLP_hands_on_2022/blob/main/Natural_Language_Understanding_WordNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "LGFil3SW_lEs"
      },
      "cell_type": "markdown",
      "source": [
        "#### Copyright 2018 Google LLC."
      ]
    },
    {
      "metadata": {
        "id": "T-ZkYPdI_pZ3"
      },
      "cell_type": "code",
      "source": [
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6jRiIjdd9LpD"
      },
      "cell_type": "markdown",
      "source": [
        "# Natural Language Understanding: WordNet\n",
        "\n",
        "Please **make a copy** of this Colab notebook before starting this lab. To do so, choose **File**->**Save a copy in Drive**.\n",
        "\n",
        "## Topics covered\n",
        "  1. Synsets\n",
        "  1. Lemmas and synonyms\n",
        "  1. Word hierarchies\n",
        "  1. Measuring similarities"
      ]
    },
    {
      "metadata": {
        "id": "adBAlLqcG-_1"
      },
      "cell_type": "markdown",
      "source": [
        "One of the earliest attempts to create useful representations of meaning for language is [WordNet](https://en.wikipedia.org/wiki/WordNet) -- a lexical database of words and their relationships.\n",
        "\n",
        "NLTK provides a [WordNet wrapper](http://www.nltk.org/howto/wordnet.html) that we'll use here."
      ]
    },
    {
      "metadata": {
        "id": "OAsJ5VRh9LpF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68568c59-a56a-4bc6-957e-3e024c95b132"
      },
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "assert(nltk.download('wordnet'))  # Make sure we have the wordnet data.\n",
        "from nltk.corpus import wordnet as wn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "_-qBFNSW9LpL"
      },
      "cell_type": "markdown",
      "source": [
        "## Synsets\n",
        "The fundamental WordNet unit is a **synset**, specified by a word form, a part of speech, and an index. The synsets() function retrieves the synsets that match the given word. For example, there are 4 synsets for the word \"surf\", one of which is a noun (n) and three of which are verbs (v). WordNet provides a definition and sometimes glosses (examples) for each synset. **Polysemy**, by the way, means having multiple senses."
      ]
    },
    {
      "metadata": {
        "id": "XpgeQO5z9LpL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d42fd3d1-1ee6-4c7c-d6d2-8a2dd0df5b6a"
      },
      "cell_type": "code",
      "source": [
        "for s in wn.synsets('surf'):\n",
        "    print (s)\n",
        "    print ('\\t', s.definition())\n",
        "    print ('\\t', s.examples())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synset('surf.n.01')\n",
            "\t waves breaking on the shore\n",
            "\t []\n",
            "Synset('surfboard.v.01')\n",
            "\t ride the waves of the sea with a surfboard\n",
            "\t ['Californians love to surf']\n",
            "Synset('browse.v.03')\n",
            "\t look around casually and randomly, without seeking anything in particular\n",
            "\t ['browse a computer directory', 'surf the internet or the world wide web']\n",
            "Synset('surf.v.03')\n",
            "\t switch channels, on television\n",
            "\t []\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "QL5YJVEv9LpO"
      },
      "cell_type": "markdown",
      "source": [
        "## Lemmas and synonyms\n",
        "Each synset includes its corresponding **lemmas** (word forms).\n",
        "\n",
        "We can construct a set of synonyms by looking up all the lemmas for all the synsets for a word."
      ]
    },
    {
      "metadata": {
        "id": "YNfv7q_t9LpP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92190b9e-b356-4329-95b6-5accd8a2070d"
      },
      "cell_type": "code",
      "source": [
        "synonyms = set()\n",
        " \n",
        "for s in wn.synsets('triumphant'):\n",
        "    for l in s.lemmas():\n",
        "        synonyms.add(l.name())\n",
        "\n",
        "print ('synonyms:', ', '.join(synonyms))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "synonyms: triumphant, prideful, jubilant, exulting, exultant, victorious, triumphal, rejoicing\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "AfM46--L9LpT"
      },
      "cell_type": "markdown",
      "source": [
        "## Word hierarchies\n",
        "WordNet organizes nouns and verbs into hierarchies according to **hypernym** or is-a relationships.\n",
        "\n",
        "Let's examine the path from \"rutabaga\" to its root in the tree, \"entity\"."
      ]
    },
    {
      "metadata": {
        "id": "pXj3S_Bj9LpT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08e545a0-3498-4c11-aa65-f90e0b8d20b3"
      },
      "cell_type": "code",
      "source": [
        "s = wn.synsets('rutabaga')\n",
        "\n",
        "while s:\n",
        "    print (s[0].hypernyms())\n",
        "    s = s[0].hypernyms()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Synset('turnip.n.02')]\n",
            "[Synset('cruciferous_vegetable.n.01'), Synset('root_vegetable.n.01')]\n",
            "[Synset('vegetable.n.01')]\n",
            "[Synset('produce.n.01')]\n",
            "[Synset('food.n.02')]\n",
            "[Synset('solid.n.01')]\n",
            "[Synset('matter.n.03')]\n",
            "[Synset('physical_entity.n.01')]\n",
            "[Synset('entity.n.01')]\n",
            "[]\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "P8PT5B989LpW"
      },
      "cell_type": "markdown",
      "source": [
        "Actually, the proper way to do this is with a transitive closure, which repeatedly applies the specified function (in this case, hypernyms())."
      ]
    },
    {
      "metadata": {
        "id": "dqY9fFIc9LpY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25cef06f-febc-440d-f49e-ae58cf2fbcc3"
      },
      "cell_type": "code",
      "source": [
        "hyper = lambda x: x.hypernyms()\n",
        "s = wn.synset('rutabaga.n.01')\n",
        "for i in list(s.closure(hyper)):\n",
        "    print (i)\n",
        "print    \n",
        "ss = wn.synset('root_vegetable.n.01')\n",
        "for i in list(ss.closure(hyper)):\n",
        "    print (i)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synset('turnip.n.02')\n",
            "Synset('cruciferous_vegetable.n.01')\n",
            "Synset('root_vegetable.n.01')\n",
            "Synset('vegetable.n.01')\n",
            "Synset('produce.n.01')\n",
            "Synset('food.n.02')\n",
            "Synset('solid.n.01')\n",
            "Synset('matter.n.03')\n",
            "Synset('physical_entity.n.01')\n",
            "Synset('entity.n.01')\n",
            "Synset('vegetable.n.01')\n",
            "Synset('produce.n.01')\n",
            "Synset('food.n.02')\n",
            "Synset('solid.n.01')\n",
            "Synset('matter.n.03')\n",
            "Synset('physical_entity.n.01')\n",
            "Synset('entity.n.01')\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "XjsWqQGf9Lpc"
      },
      "cell_type": "markdown",
      "source": [
        "## Measuring similarity\n",
        "\n",
        "WordNet's word hierarchies (for nouns and verbs) allow us to measure similarity in various ways.\n",
        "\n",
        "Path similarity is defined as:\n",
        "\n",
        "> $1 / (ShortestPathDistance(s_1, s_2) + 1)$\n",
        "\n",
        "where $ShortestPathDistance(s_1, s_2)$ is computed from the hypernym/hyponym graph.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "ETH-GG-A9Lpc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b78cf764-8e13-438d-a978-c6bc45770dfc"
      },
      "cell_type": "code",
      "source": [
        "s1 = wn.synset('dog.n.01')\n",
        "s2 = wn.synset('cat.n.01')\n",
        "s3 = wn.synset('potato.n.01')\n",
        "\n",
        "print (s1, '::', s1, s1.path_similarity(s1))\n",
        "print (s1, '::', s2, s1.path_similarity(s2))\n",
        "print (s1, '::', s3, s1.path_similarity(s3))\n",
        "print (s2, '::', s3, s2.path_similarity(s3))\n",
        "\n",
        "print\n",
        "\n",
        "hyper = lambda x: x.hypernyms()\n",
        "\n",
        "print(s1.hypernyms())\n",
        "\n",
        "for i in list(s1.closure(hyper)):\n",
        "    print (i)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synset('dog.n.01') :: Synset('dog.n.01') 1.0\n",
            "Synset('dog.n.01') :: Synset('cat.n.01') 0.2\n",
            "Synset('dog.n.01') :: Synset('potato.n.01') 0.07142857142857142\n",
            "Synset('cat.n.01') :: Synset('potato.n.01') 0.05263157894736842\n",
            "[Synset('canine.n.02'), Synset('domestic_animal.n.01')]\n",
            "Synset('canine.n.02')\n",
            "Synset('domestic_animal.n.01')\n",
            "Synset('carnivore.n.01')\n",
            "Synset('animal.n.01')\n",
            "Synset('placental.n.01')\n",
            "Synset('organism.n.01')\n",
            "Synset('mammal.n.01')\n",
            "Synset('living_thing.n.01')\n",
            "Synset('vertebrate.n.01')\n",
            "Synset('whole.n.02')\n",
            "Synset('chordate.n.01')\n",
            "Synset('object.n.01')\n",
            "Synset('physical_entity.n.01')\n",
            "Synset('entity.n.01')\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "EsiZ9u4X9Lpg"
      },
      "cell_type": "markdown",
      "source": [
        "## Takeaways\n",
        "\n",
        "WordNet gives us ways to compare words and understand their relationships in a much more meaningful way than relying on the raw strings (sequences of characters). We know that 'cat' and 'dog', for example, are somewhat similar even though they have no string similarity. As a result, WordNet has been used in lots of practical applications over the years. However, WordNet has a few important shortcomings:\n",
        "\n",
        "1. WordNet was built by people. This makes it hard to maintain as new words are added (e.g. 'iphone' isn't in WordNet) and definitions evolve. It also has limited language coverage. NLTK wraps Open Multilingual WordNet which includes 22 additional languages, but these are less extensive than the English WordNet. A fundamental question addressed by subsequent sections is: can we build WordNet-like resources automatically from text, of which there is an abundance?\n",
        "\n",
        "1. WordNet, like any dictionary or thesaurus, represents the meaning of a word with its relationships to other words. That is, it lacks *grounding* in the real world. This is fine for people who have plenty of working knowledge of the world, who have seen and interacted with dogs and cats and potatoes, but would be much less helpful for aliens arriving on Earth for the first time. This deficiency, where language is only defined with respect to itself, and not with respect to images for example, is at the frontier of research in Natural Language Understanding."
      ]
    },
    {
      "metadata": {
        "id": "x1BObDhU9Lpg"
      },
      "cell_type": "markdown",
      "source": [
        "## Quiz Questions\n",
        "\n",
        "(1) Use the closure function to enumerate the **hyponyms** (the inverse of a hypernym) of 'root_vegetable.n.01'.\n",
        "\n",
        "(2) We used the path_similarity function to compute the similarity between 'dog' and 'cat'. Use the hypernyms() function (see above) to find the path between these two words. Does the path similarity 0.2 make sense?"
      ]
    }
  ]
}